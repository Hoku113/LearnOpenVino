{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Pose Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from openvino.runtime import Core\n",
    "\n",
    "from decoder import OpenPoseDecoder\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "import notebook_utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_dir = \"model\"\n",
    "\n",
    "model_name = \"human-pose-estimation-0001\"\n",
    "\n",
    "precision = \"FP16-INT8\"\n",
    "\n",
    "model_path = f\"model/intel/{model_name}/{precision}/{model_name}.xml\"\n",
    "model_weights_path = f\"model/intel/{model_name}/{precision}/{model_name}.bin\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    download_command = f\"omz_downloader --name {model_name} --precision {precision} --output_dir {base_model_dir}\"\n",
    "\n",
    "    ! $download_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie_core = Core()\n",
    "\n",
    "model = ie_core.read_model(model_path, model_weights_path)\n",
    "compiled_model = ie_core.compile_model(model, device_name=\"CPU\")\n",
    "\n",
    "#  Get the input and output anmes of nodes.\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layers = list(compiled_model.outputs)\n",
    "\n",
    "# debug\n",
    "print(input_layer)\n",
    "print(output_layers)\n",
    "\n",
    "# get the input size\n",
    "height, width = list(input_layer.shape)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show height, width\n",
    "print(height, width) # (256, 456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer.any_name, [o.any_name for o in output_layers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing\n",
    "\n",
    "### OpenPoseDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = OpenPoseDecoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D pooling in numpy (from: https://stackoverflow.com/a/54966908/1624463)\n",
    "def pool2d(A, kernel_size, stride, padding, pool_mode=\"max\"):\n",
    "    \"\"\"\n",
    "    2D Pooling\n",
    "\n",
    "    Parameters:\n",
    "    A: input 2D array\n",
    "    stride: int, the stride of the window\n",
    "    padding: int, implicit zero paddings on both sides of the input\n",
    "    pool_mode: string, 'max' or 'avg'\n",
    "    \"\"\"\n",
    "\n",
    "    A = np.pad(A, padding, mode=\"constant\")\n",
    "\n",
    "    # check\n",
    "    # print(A)\n",
    "\n",
    "    # Window view of A\n",
    "    output_shape = (\n",
    "        (A.shape[0] - kernel_size) // stride + 1,\n",
    "        (A.shape[1] - kernel_size) // stride + 1,\n",
    "    )\n",
    "\n",
    "\n",
    "    kernel_size = (kernel_size, kernel_size)\n",
    "    A_w = as_strided(\n",
    "        A,\n",
    "        shape=output_shape + kernel_size,\n",
    "        strides=(stride * A.strides[0], stride * A.strides[1]) + A.strides\n",
    "    )\n",
    "\n",
    "    A_w = A_w.reshape(-1, *kernel_size)\n",
    "\n",
    "    # Return the result of pooling\n",
    "    if pool_mode == \"max\":\n",
    "        return A_w.max(axis=(1, 2)).reshape(output_shape)\n",
    "    elif pool_mode == \"avg\":\n",
    "        return A_w.mean(axis=(1, 2)).reshape(output_shape)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# non maximum suppression\n",
    "def heatmap_nms(heatmaps, pooled_heatmaps):\n",
    "    return heatmaps * (heatmaps == pooled_heatmaps)\n",
    "\n",
    "\n",
    "# Get poses from results.\n",
    "def process_results(img, pafs, heatmaps):\n",
    "    # This processing comes from\n",
    "    # https://github.com/openvinotoolkit/open_model_zoo/blob/master/demos/common/python/models/open_pose.py\n",
    "    \n",
    "    pooled_heatmaps = np.array(\n",
    "        [[pool2d(h, kernel_size=3, stride=1, padding=1, pool_mode=\"max\") for h in heatmaps[0]]]\n",
    "    )\n",
    "    nms_heatmaps = heatmap_nms(heatmaps, pooled_heatmaps)\n",
    "\n",
    "    # Decode poses.\n",
    "    poses, scores = decoder(heatmaps, nms_heatmaps, pafs)\n",
    "    output_shape = list(compiled_model.output(index=0).partial_shape)\n",
    "    output_scale = img.shape[1] / output_shape[3].get_length(), img.shape[0] / output_shape[2].get_length()\n",
    "\n",
    "    poses[:, :, :2] *= output_scale\n",
    "    return poses, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Pose Overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ((255, 0, 0), (255, 0, 255), (170, 0, 255), (255, 0, 85), (255, 0, 170), (85, 255, 0),\n",
    "          (255, 170, 0), (0, 255, 0), (255, 255, 0), (0,\n",
    "                                                      255, 85), (170, 255, 0), (0, 85, 255),\n",
    "          (0, 255, 170), (0, 0, 255), (0, 255, 255), (85, 0, 255), (0, 170, 255))\n",
    "\n",
    "default_skeleton = ((15, 13), (13, 11), (16, 14), (14, 12), (11, 12), (5, 11), (6, 12), (5, 6), (5, 7),\n",
    "                   (6, 8), (7, 9), (8, 10), (1, 2), (0, 1), (0, 2), (1, 3), (2, 4), (3, 5), (4, 6))\n",
    "\n",
    "def draw_poses(img, poses, point_score_threshold, skeleton=default_skeleton):\n",
    "    if poses.size == 0:\n",
    "        return img\n",
    "    \n",
    "    img_limbs = np.copy(img)\n",
    "    for pose in poses:\n",
    "        points = pose[:, :2].astype(np.int32)\n",
    "        points_scores = pose[:, 2]\n",
    "\n",
    "        for i, (p, v) in enumerate(zip(points, points_scores)):\n",
    "            if v > point_score_threshold:\n",
    "                cv2.circle(img, tuple(p), 1, colors[i], 2)\n",
    "\n",
    "        for i, j in skeleton:\n",
    "            if points_scores[i] > point_score_threshold and points_scores[j] > point_score_threshold:\n",
    "                cv2.line(img_limbs, tuple(points[i]), tuple(points[j]), color=colors[j], thickness=4)\n",
    "    \n",
    "    cv2.addWeighted(img, 0.4, img_limbs, 0.6 , 0, dst=img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pose_estimation(source=0, flip=False, use_popup=False, skip_first_frames=0):\n",
    "    pafs_output_key = compiled_model.output(\"Mconv7_stage2_L1\")\n",
    "    heatmaps_output_key = compiled_model.output(\"Mconv7_stage2_L2\")\n",
    "    player = None\n",
    "\n",
    "    try:\n",
    "        # Create a video player to play with target fps.\n",
    "        player = utils.VideoPlayer(\n",
    "            source, flip=flip, fps=30, skip_first_frames=skip_first_frames)\n",
    "\n",
    "        player.start()\n",
    "\n",
    "        if use_popup:\n",
    "            title = \"Press ESC to Exit\"\n",
    "            cv2.namedWindow(title, cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "        processing_times = collections.deque()\n",
    "\n",
    "        while True:\n",
    "            frame = player.next()\n",
    "            if frame is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "\n",
    "            # If the frame is larger than full HD, reduce size to improve the performance\n",
    "            scale = 1280 / max(frame.shape)\n",
    "            if scale < 1:\n",
    "                frame = cv2.resize(frame, None, fx=scale,\n",
    "                                interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # Resize the image and change dims to fit neaural network input\n",
    "            # (see https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/human-pose-estimation-0001)\n",
    "            input_img = cv2.resize(frame, (width, height),\n",
    "                                interpolation=cv2.INTER_AREA)\n",
    "            input_img = input_img.transpose((2, 0, 1))[np.newaxis, ...]\n",
    "\n",
    "            start_time = time.perf_counter()\n",
    "            results = compiled_model([input_img])\n",
    "            stop_time = time.perf_counter()\n",
    "\n",
    "            pafs = results[pafs_output_key]\n",
    "            heatmaps = results[heatmaps_output_key]\n",
    "\n",
    "            print(pafs.shape)\n",
    "            print(heatmaps.shape)\n",
    "\n",
    "            # Get poses from network results\n",
    "            poses, scores = process_results(frame, pafs, heatmaps)\n",
    "\n",
    "            print(poses)\n",
    "\n",
    "            # draw poses on a frame\n",
    "            frame = draw_poses(frame, poses, 0.1)\n",
    "\n",
    "            processing_times.append(stop_time - start_time)\n",
    "            if len(processing_times) > 200:\n",
    "                processing_times.popleft()\n",
    "\n",
    "            _, f_width = frame.shape[:2]\n",
    "            processing_time = np.mean(processing_times) * 1000\n",
    "            fps = 1000 / processing_time\n",
    "\n",
    "            cv2.putText(frame, f\"Inference time: {processing_time:.1f}ms ({fps:.1f} FPS)\", (20, 40),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, f_width / 1000, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "            \n",
    "            if use_popup:\n",
    "                cv2.imshow(title, frame)\n",
    "                key = cv2.waitKey(1)\n",
    "                if key == 27:\n",
    "                    break\n",
    "            else:\n",
    "                # Encode numpy array to jpg\n",
    "                _, encoded_img = cv2.imencode(\".jpg\", frame, params=[cv2.IMWRITE_JPEG_QUALITY, 90])\n",
    "                \n",
    "                i = display.Image(data=encoded_img)\n",
    "\n",
    "                # dispaly image in this notebook\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(i)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if player is not None:\n",
    "            player.stop()\n",
    "        if use_popup:\n",
    "            cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "\n",
    "### Run live pose estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pose_estimation(source=0, flip=False, use_popup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = \"https://github.com/intel-iot-devkit/sample-videos/blob/master/store-aisle-detection.mp4?raw=true\"\n",
    "\n",
    "run_pose_estimation(video_file, flip=False, use_popup=False, skip_first_frames=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.openvino-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0799a591d602a7578f1ccf5f8e7829399f6cceabacecc6a7299b85400bce773"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
