{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Entity Etraction with OpenVINO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import tokens_bert as tokens\n",
    "\n",
    "from openvino.runtime import Core\n",
    "from openvino.runtime import Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A directory where the model will be downloaded\n",
    "base_model_dir = \"model\"\n",
    "\n",
    "# The desired precision.\n",
    "precision = \"FP16-INT8\"\n",
    "\n",
    "# A model name as named in Open Model Zoo\n",
    "model_name = \"bert-small-uncased-whole-word-masking-squad-int8-0002\"\n",
    "\n",
    "model_path = f\"model/intel/{model_name}/{precision}/{model_name}.xml\"\n",
    "model_weights_path = f\"model/intel/{model_name}/{precision}/{model_name}.bin\"\n",
    "\n",
    "download_command = f\"omz_downloader \" \\\n",
    "                   f\"--name {model_name} \" \\\n",
    "                   f\"--precision {precision} \" \\\n",
    "                   f\"--output_dir {base_model_dir} \" \\\n",
    "                   f\"--cache_dir {base_model_dir}\"\n",
    "\n",
    "! $download_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model for Entity Extraction with Dynamic Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenVINO Runtime\n",
    "ie = Core()\n",
    "\n",
    "model = ie.read_model(model=model_path, weights=model_weights_path)\n",
    "\n",
    "# Assign dynamic shapes to every input layer on the last dimension\n",
    "for input_layer in model.inputs:\n",
    "    input_shape = input_layer.partial_shape\n",
    "    input_shape[1] = Dimension(1, 384)\n",
    "    model.reshape({input_layer: input_shape})\n",
    "\n",
    "    # debug\n",
    "    print(input_shape)\n",
    "\n",
    "# Compile the model for CPU\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "# Get input names of nodes\n",
    "input_keys = list(compiled_model.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.any_name for i in input_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A path to a vocabulary file\n",
    "vocab_file_path = \"data/vocab.txt\"\n",
    "\n",
    "# Create a dictionary with words and their indices\n",
    "vocab = tokens.load_vocab_file(vocab_file_path)\n",
    "\n",
    "# Define special tokens\n",
    "cls_token = vocab[\"[CLS]\"]\n",
    "sep_token = vocab[\"[SEP]\"]\n",
    "\n",
    "# Set a confidence score threshold\n",
    "confidence_threshold = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A generator of a sequence of inputs\n",
    "def prepare_input(entity_tokens, context_tokens):\n",
    "    input_ids = [cls_token] + entity_tokens + [sep_token] + \\\n",
    "        context_tokens + [sep_token]\n",
    "    \n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    token_type_ids = [0] * (len(entity_tokens) + 2) + \\\n",
    "        [1] * (len(context_tokens) + 1)\n",
    "    \n",
    "    # check \n",
    "    print(attention_mask)\n",
    "    print(token_type_ids)\n",
    "\n",
    "    # Create an input to feed the model\n",
    "    input_dict = {\n",
    "        \"input_ids\": np.array([input_ids], dtype=np.int32),\n",
    "        \"attention_mask\": np.array([attention_mask], dtype=np.int32),\n",
    "        \"token_type_ids\": np.array([token_type_ids], dtype=np.int32)\n",
    "    }\n",
    "\n",
    "    # Some models require additional position_ids\n",
    "    if \"position_ids\" in [i_key.any_name for i_key in input_keys]:\n",
    "        position_ids = np.arange(len(input_ids))\n",
    "        input_dict[\"position_ids\"] = np.array([position_ids], dtype=np.int32)\n",
    "\n",
    "    return input_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_entity_window(start_score, end_score,\n",
    "                             context_start_idx, context_end_idx):\n",
    "\n",
    "    context_len = context_end_idx - context_start_idx\n",
    "    score_mat = np.matmul(\n",
    "        start_score[context_start_idx:context_end_idx].reshape(\n",
    "            (context_len, 1)),\n",
    "        end_score[context_start_idx:context_end_idx].reshape(\n",
    "            (1, context_len)),            \n",
    "    )\n",
    "\n",
    "    score_mat = np.triu(score_mat)\n",
    "    score_mat = np.tril(score_mat, 16)\n",
    "\n",
    "    max_s, max_e = divmod(score_mat.flatten().argmax(), score_mat.shape[1])\n",
    "    max_score = score_mat[max_s, max_e]\n",
    "\n",
    "    return max_score, max_s, max_e\n",
    "\n",
    "\n",
    "def postprocess(output_start, output_end, entity_tokens,\n",
    "                context_tokens_start_end, input_size):\n",
    "\n",
    "    def get_score(logits):\n",
    "        out = np.exp(logits)\n",
    "        return out / out.sum(axis=-1)\n",
    "\n",
    "    # Get start-end scores for the context\n",
    "    score_start = get_score(output_start)\n",
    "    score_end = get_score(output_end)\n",
    "\n",
    "    context_start_idx = len(entity_tokens) + 2\n",
    "    context_end_idx = input_size - 1\n",
    "\n",
    "    # Find the product of all start-end combinations to find the best one.\n",
    "    max_score, max_start, max_end = find_best_entity_window(\n",
    "        start_score=score_start, end_score=score_end,\n",
    "        context_start_idx=context_start_idx, context_end_idx=context_end_idx\n",
    "    )\n",
    "\n",
    "    max_start = context_tokens_start_end[max_start][0]\n",
    "    max_end = context_tokens_start_end[max_end][1]\n",
    "\n",
    "    return max_score, max_start, max_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_entity(entity, context, vocab):\n",
    "\n",
    "    context_tokens, context_tokens_end = tokens.text_to_tokens(\n",
    "        text=context.lower(), vocab=vocab)\n",
    "\n",
    "    entity_tokens, _ = tokens.text_to_tokens(text=entity.lower(), vocab=vocab)\n",
    "\n",
    "    network_input = prepare_input(entity_tokens, context_tokens)\n",
    "    input_size = len(context_tokens) + len(entity_tokens) + 3\n",
    "\n",
    "    # OpenVINO inference.\n",
    "    output_start_key = compiled_model.output(\"output_s\")\n",
    "    output_end_key = compiled_model.output(\"output_e\")\n",
    "    result = compiled_model(network_input)\n",
    "\n",
    "    # Postprocess the result getting the score and context range for the answer.\n",
    "    score_start_end = postprocess(output_start=result[output_start_key][0],\n",
    "                                  output_end=result[output_end_key][0],\n",
    "                                  entity_tokens=entity_tokens,\n",
    "                                  context_tokens_start_end=context_tokens_end,\n",
    "                                  input_size=input_size)\n",
    "\n",
    "    return context[score_start_end[1]:score_start_end[2]], score_start_end[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Entity Recognition Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = [\"building\", \"company\", \"persons\", \"city\",\n",
    "            \"state\", \"height\", \"floor\", \"address\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analyze_entities(context):\n",
    "    print(f\"Context: {context}\\n\", flush=True)\n",
    "\n",
    "    if len(context) == 0:\n",
    "        print(\"Error: Empty context or outside paragraphs\")\n",
    "        return\n",
    "\n",
    "    if len(context) > 380:\n",
    "        print(\"Error: The context is too long for this particular model. Try with context shorter than 380 words\")\n",
    "        return\n",
    "\n",
    "    # Measure the processing time\n",
    "    start_time = time.perf_counter()\n",
    "    extract = []\n",
    "    for field in template:\n",
    "        entity_to_find = field + \"?\"\n",
    "        entity, score = get_best_entity(entity=entity_to_find,\n",
    "                                        context=context,\n",
    "                                        vocab=vocab)\n",
    "        if score >= confidence_threshold:\n",
    "            extract.append({\"Entity\": entity, \"Type\": field,\n",
    "                            \"Score\": f\"{score:.2f}\"})\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    res = {\"Extraction\": extract, \"Time\": f\"{end_time - start_time:.2f}s\"}\n",
    "    print(\"\\nJSON Output:\")\n",
    "    print(json.dumps(res, sort_keys=False, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on Simple Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = \"Intel Corporation is an American multinational and technology\" \\\n",
    "    \" company headquartered in Santa Clara, California.\"\n",
    "\n",
    "run_analyze_entities(source_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = \"Intel was founded in Mountain View, California, \" \\\n",
    "    \"in 1968 by Gordon E. Moore, a chemist, and Robert Noyce, \" \\\n",
    "    \"a physicist and co-inventor of the integrated circuit\"\n",
    "\n",
    "run_analyze_entities(source_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = \"The Robert Noyce Building in Santa Clara, California, \" \\\n",
    "    \"is the headquarters for Intel Corporation. It was constructed in 1992 \" \\\n",
    "    \"and is located at 2200 Mission College Boulevard - 95054. It has an \" \\\n",
    "    \"estimated height of 22.20 meters and 6 floors above ground.\"\n",
    "run_analyze_entities(source_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.openvino-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c72c11d2d2d54e76eb9b9746a9dfd04f5bf9e7b246a1d2f2ce53b6ae392c21ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
