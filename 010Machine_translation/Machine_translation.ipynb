{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine translation demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openvino.runtime import Core\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tokenizers import SentencePieceBPETokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! omz_downloader --name machine-translation-nar-en-de-0002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core = Core()\n",
    "model = core.read_model('intel/machine-translation-nar-en-de-0002/FP32/machine-translation-nar-en-de-0002.xml')\n",
    "compiled_model = core.compile_model(model)\n",
    "input_name = 'tokens'\n",
    "output_name = 'pred'\n",
    "model.output(output_name)\n",
    "max_tokens = model.input(input_name).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = SentencePieceBPETokenizer.from_file(\n",
    "    './intel/machine-translation-nar-en-de-0002/tokenizer_src/vocab.json',\n",
    "    './intel/machine-translation-nar-en-de-0002/tokenizer_src/merges.txt'\n",
    ")\n",
    "\n",
    "tgt_tokenizer = SentencePieceBPETokenizer.from_file(\n",
    "    './intel/machine-translation-nar-en-de-0002/tokenizer_tgt/vocab.json',\n",
    "    './intel/machine-translation-nar-en-de-0002/tokenizer_tgt/merges.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence: str) -> str:\n",
    "    \"\"\"\n",
    "    Tokenize the sentence using the downloaded tokenizer and run the model,\n",
    "    whose output is decoded into a human readable string\n",
    "\n",
    "    :param sentence: a strig containing the phrase to be translated\n",
    "    :return: the translated string\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove leading and trailing white spaces\n",
    "    sentence = sentence.strip()\n",
    "    assert len(sentence) > 0\n",
    "    tokens = src_tokenizer.encode(sentence).ids\n",
    "\n",
    "    # Transform the tokenized sentence into the model's input format\n",
    "    tokens = [src_tokenizer.token_to_id('<s>')] + \\\n",
    "        tokens + [src_tokenizer.token_to_id('</s>')]\n",
    "    pad_length = max_tokens - len(tokens)\n",
    "\n",
    "    # If the sentence size is less than the maximum allowed tokens,\n",
    "    # fill the remaining tokens with '<pad>'\n",
    "\n",
    "    if pad_length > 0:\n",
    "        tokens = tokens + [src_tokenizer.token_to_id('<pad>')] * pad_length\n",
    "    assert len(tokens) == max_tokens, \"input sentence is too long\"\n",
    "    encoded_sentence = np.array(tokens).reshape(1, -1)\n",
    "\n",
    "    # Perform inference\n",
    "    enc_translated = compiled_model({input_name: encoded_sentence})\n",
    "    output_key = compiled_model.output(output_name)\n",
    "    enc_translated = enc_translated[output_key][0]\n",
    "\n",
    "    # Decode sentence\n",
    "    sentence = tgt_tokenizer.decode(enc_translated)\n",
    "\n",
    "    # Remove <pad> tokens, as well as '<s>' and '</s>' tokens which mark the\n",
    "    # beginning and ending of the sentence\n",
    "    for s in ['</s>', '<s>', '<pad>']:\n",
    "        sentence = sentence.replace(s, '')\n",
    "\n",
    "    # Transform sentence into lower case and join words by a white space\n",
    "    sentence = sentence.lower().split()\n",
    "    sentence = \" \".join(key for key, _ in itertools.groupby(sentence))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_translator():\n",
    "    \"\"\"\n",
    "    Run the translation in real time, reading the input from the user.\n",
    "    This function prints the translated sentence and the time\n",
    "    spent during inference\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        input_sentence = input()\n",
    "        if input_sentence == \"\":\n",
    "            break\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        translated = translate(input_sentence)\n",
    "        end_time = time.perf_counter()\n",
    "        print(f'translated: {translated}')\n",
    "        print(f'Time: {end_time - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"My name is Hokuto\"\n",
    "print(f\"translated: {translate(sentence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live stream translation\n",
    "run_translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.openvino-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0799a591d602a7578f1ccf5f8e7829399f6cceabacecc6a7299b85400bce773"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
