{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert PyTorch model to ONNX and OpenVINO IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import Markdown, display\n",
    "from fastseg import MobileV3Large\n",
    "from openvino.runtime import Core\n",
    "\n",
    "from notebook_utils import CityScapesSegmentation, segmentation_map_to_image, viz_result_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 1024  # Suggested values: 2048, 1024 or 512. The minimum width is 512.\n",
    "# Set IMAGE_HEIGHT manually for custom input sizes. Minimum height is 512\n",
    "IMAGE_HEIGHT = 1024 if IMAGE_WIDTH == 2048 else 512\n",
    "DIRECTORY_NAME = \"model\"\n",
    "BASE_MODEL_NAME = DIRECTORY_NAME + f\"/fastseg{IMAGE_WIDTH}\"\n",
    "\n",
    "# Paths where PyTorch, ONNX and OpenVINO IR models will be stored\n",
    "model_path = Path(BASE_MODEL_NAME).with_suffix(\".pth\")\n",
    "onnx_path = model_path.with_suffix(\".onnx\")\n",
    "ir_path = model_path.with_suffix(\".xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Fastseg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the Fastseg model (if it has not been downloaded before)....\n",
      "Loading pretrained model mobilev3large-lraspp with F=128...\n",
      "Loaded PyTorch Fastseg model\n",
      "Model saved at model\\fastseg1024.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading the Fastseg model (if it has not been downloaded before)....\")\n",
    "model = MobileV3Large.from_pretrained().eval()\n",
    "print(\"Loaded PyTorch Fastseg model\")\n",
    "\n",
    "# Save the model\n",
    "model_path.parent.mkdir(exist_ok=True)\n",
    "torch.save(model.state_dict(), str(model_path))\n",
    "print(f\"Model saved at {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX model Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert PyTorch model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model model\\fastseg1024.onnx already exists.\n"
     ]
    }
   ],
   "source": [
    "if not onnx_path.exists():\n",
    "    dummy_input = torch.randn(1, 3, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "\n",
    "    # For the Fastseg model, setting do_constant_folding to False is required\n",
    "    # for PyTorch>1.5.1\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True\n",
    "    )\n",
    "    print(f\"ONNX model exported to {onnx_path}.\")\n",
    "else:\n",
    "    print(f\"ONNX model {onnx_path} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer command to convert the ONNX model to openVINO\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "`mo --input_model \"model\\fastseg1024.onnx\" --input_shape \"[1, 3, 512, 1024]\" --mean_values=\"[123.675, 116.28, 103.53]\" --scale_values=\"[58.395, 57.12, 57.375]\" --data_type FP16 --output_dir \"model\"`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mo_command = f\"\"\"mo\n",
    "                 --input_model \"{onnx_path}\"\n",
    "                 --input_shape \"[1, 3, {IMAGE_HEIGHT}, {IMAGE_WIDTH}]\"\n",
    "                 --mean_values=\"[123.675, 116.28, 103.53]\"\n",
    "                 --scale_values=\"[58.395, 57.12, 57.375]\"\n",
    "                 --data_type FP16\n",
    "                 --output_dir \"{model_path.parent}\"\n",
    "\"\"\"\n",
    "\n",
    "mo_command = \" \".join(mo_command.split())\n",
    "print(\"Model Optimizer command to convert the ONNX model to openVINO\")\n",
    "display(Markdown(f\"`{mo_command}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting ONNX model to IR... This may take a few minutes\n",
      "C:\\Users\\hokuto\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pkg_resources\\__init__.py:123: PkgResourcesDeprecationWarning: 079eae91b01d7666471c9e01dadd031e2c2a00f2- is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "C:\\Users\\hokuto\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pkg_resources\\__init__.py:123: PkgResourcesDeprecationWarning: 079eae91b01d7666471c9e01dadd031e2c2a00f2- is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tc:\\Users\\hokuto\\Desktop\\practice\\LearnOpenVino\\006ConvertModel\\model\\fastseg1024.onnx\n",
      "\t- Path for generated IR: \tc:\\Users\\hokuto\\Desktop\\practice\\LearnOpenVino\\006ConvertModel\\model\n",
      "\t- IR output name: \tfastseg1024\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1, 3, 512, 1024]\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \t[123.675, 116.28, 103.53]\n",
      "\t- Scale values: \t[58.395, 57.12, 57.375]\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- User transformations: \tNot specified\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Enable IR generation for fixed input shape: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "Advanced parameters:\n",
      "\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "C:\\Users\\hokuto\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pkg_resources\\__init__.py:123: PkgResourcesDeprecationWarning: 079eae91b01d7666471c9e01dadd031e2c2a00f2- is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "OpenVINO runtime found in: \tC:\\Users\\hokuto\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openvino\n",
      "OpenVINO runtime version: \t2022.1.0-7019-cdb9bec7210-releases/2022/1\n",
      "Model Optimizer version: \t2022.1.0-7019-cdb9bec7210-releases/2022/1\n",
      "[ ERROR ]  -------------------------------------------------\n",
      "[ ERROR ]  ----------------- INTERNAL ERROR ----------------\n",
      "[ ERROR ]  Unexpected exception happened.\n",
      "[ ERROR ]  Please contact Model Optimizer developers and forward the following information:\n",
      "[ ERROR ]  While validating ONNX node '<Node(Concat): Concat_42>':\n",
      "Check 'ov::PartialShape::merge_into(inputs_shape_scheme, this_input_shape)' failed at C:\\j\\workspace\\private-ci\\ie\\build-windows-vs2019@3\\b\\repos\\openvino\\src\\core\\src\\op\\concat.cpp:74:\n",
      "While validating node 'v0::Concat Concat_228 (399[0]:i64{4,1}, 400[0]:i64{4}) -> (dynamic...)' with friendly_name 'Concat_228':\n",
      "Argument shapes are inconsistent; they must have the same rank, and must have equal dimension everywhere except on the concatenation axis (axis 0).\n",
      "\n",
      "[ ERROR ]  Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hokuto\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\openvino\\tools\\mo\\main.py\", line 533, in main\n",
      "    ret_code = driver(argv)\n",
      "  File \"C:\\Users\\hokuto\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\openvino\\tools\\mo\\main.py\", line 489, in driver\n",
      "    graph, ngraph_function = prepare_ir(argv)\n",
      "  File \"C:\\Users\\hokuto\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\openvino\\tools\\mo\\main.py\", line 394, in prepare_ir\n",
      "    ngraph_function = moc_pipeline(argv, moc_front_end)\n",
      "  File \"C:\\Users\\hokuto\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openvino\\tools\\mo\\moc_frontend\\pipeline.py\", line 147, in moc_pipeline\n",
      "    ngraph_function = moc_front_end.convert(input_model)\n",
      "RuntimeError: While validating ONNX node '<Node(Concat): Concat_42>':\n",
      "Check 'ov::PartialShape::merge_into(inputs_shape_scheme, this_input_shape)' failed at C:\\j\\workspace\\private-ci\\ie\\build-windows-vs2019@3\\b\\repos\\openvino\\src\\core\\src\\op\\concat.cpp:74:\n",
      "While validating node 'v0::Concat Concat_228 (399[0]:i64{4,1}, 400[0]:i64{4}) -> (dynamic...)' with friendly_name 'Concat_228':\n",
      "Argument shapes are inconsistent; they must have the same rank, and must have equal dimension everywhere except on the concatenation axis (axis 0).\n",
      "\n",
      "\n",
      "[ ERROR ]  ---------------- END OF BUG REPORT --------------\n",
      "[ ERROR ]  -------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not ir_path.exists():\n",
    "    print(\"Exporting ONNX model to IR... This may take a few minutes\")\n",
    "    mo_result = %sx $mo_command\n",
    "    print(\"\\n\".join(mo_result))\n",
    "else:\n",
    "    print(f\"IR model {ir_path} already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image: np.ndarray) -> np.ndarray:\n",
    "    image = image.astype(np.float32)\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    image /= 255.0\n",
    "    image -= mean\n",
    "    image /= std\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filename = \"data/street.jpg\"\n",
    "image = cv2.cvtColor(cv2.imread(image_filename), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "resized_image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "normalized_image = normalize(resized_image)\n",
    "\n",
    "# Convert the resized images to network input shape\n",
    "input_image = np.expand_dims(np.transpose(resized_image, (2, 0, 1)), 0)\n",
    "normalized_input_image = np.expand_dims(np.transpose(normalized_image, (2, 0, 1)), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the OpenVINO IR Network and Run Inference on the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "While validating ONNX node '<Node(Concat): Concat_42>':\nCheck 'ov::PartialShape::merge_into(inputs_shape_scheme, this_input_shape)' failed at C:\\j\\workspace\\private-ci\\ie\\build-windows-vs2019@3\\b\\repos\\openvino\\src\\core\\src\\op\\concat.cpp:74:\nWhile validating node 'v0::Concat Concat_228 (399[0]:i64{4,1}, 400[0]:i64{4}) -> (dynamic...)' with friendly_name 'Concat_228':\nArgument shapes are inconsistent; they must have the same rank, and must have equal dimension everywhere except on the concatenation axis (axis 0).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mセル16 を c:\\Users\\hokuto\\Desktop\\practice\\LearnOpenVino\\006ConvertModel\\convertmodel.ipynb\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hokuto/Desktop/practice/LearnOpenVino/006ConvertModel/convertmodel.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ie \u001b[39m=\u001b[39m Core()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hokuto/Desktop/practice/LearnOpenVino/006ConvertModel/convertmodel.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_onnx \u001b[39m=\u001b[39m ie\u001b[39m.\u001b[39;49mread_model(model\u001b[39m=\u001b[39;49monnx_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hokuto/Desktop/practice/LearnOpenVino/006ConvertModel/convertmodel.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m compiled_model_onnx \u001b[39m=\u001b[39m ie\u001b[39m.\u001b[39mcompile_model(model\u001b[39m=\u001b[39mmodel_onnx, device_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCPU\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hokuto/Desktop/practice/LearnOpenVino/006ConvertModel/convertmodel.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m output_layer_onnx \u001b[39m=\u001b[39m compiled_model_onnx\u001b[39m.\u001b[39moutput(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: While validating ONNX node '<Node(Concat): Concat_42>':\nCheck 'ov::PartialShape::merge_into(inputs_shape_scheme, this_input_shape)' failed at C:\\j\\workspace\\private-ci\\ie\\build-windows-vs2019@3\\b\\repos\\openvino\\src\\core\\src\\op\\concat.cpp:74:\nWhile validating node 'v0::Concat Concat_228 (399[0]:i64{4,1}, 400[0]:i64{4}) -> (dynamic...)' with friendly_name 'Concat_228':\nArgument shapes are inconsistent; they must have the same rank, and must have equal dimension everywhere except on the concatenation axis (axis 0).\n"
     ]
    }
   ],
   "source": [
    "ie = Core()\n",
    "model_onnx = ie.read_model(model=onnx_path)\n",
    "compiled_model_onnx = ie.compile_model(model=model_onnx, device_name=\"CPU\")\n",
    "\n",
    "output_layer_onnx = compiled_model_onnx.output(0)\n",
    "\n",
    "res_onnx = compiled_model_onnx([normalized_input_image])[output_layer_onnx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert network result to segmentation map and display the result\n",
    "result_mask_onnx = np.squeeze(np.argmax(res_onnx, axis=1)).astype(np.uint8)\n",
    "viz_result_image(\n",
    "    image,\n",
    "    segmentation_map_to_image(result_mask_onnx, CityScapesSegmentation.get_colormap()),\n",
    "    resize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IR Model in Inference Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "model_ir = ie.read_model(model=ir_path)\n",
    "compiled_model_ir = ie.compile_model(model=model_ir, device_name=\"CPU\")\n",
    "\n",
    "input_layer_ir = next(iter(compiled_model_ir.inputs))\n",
    "output_layer_ir = next(iter(compiled_model_ir.outputs))\n",
    "\n",
    "res_ir = compiled_model_ir([input_image])[output_layer_ir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_mask_ir = np.squeeze(np.argmax(res_ir, axis=1)).astype(np.uint8)\n",
    "viz_result_image(\n",
    "    image,\n",
    "    segmentation_map_to_image(result=result_mask_ir, colormap=CityScapesSegmentation.get_colormap()),\n",
    "    resize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    result_torch = model(torch.as_tensor(normalized_input_image).float())\n",
    "\n",
    "result_mask_torch = torch.argmax(result_torch, dim=1).squeeze(0).numpy().astype(np.uint8)\n",
    "viz_result_image(\n",
    "    image,\n",
    "    segmentation_map_to_image(result=result_mask_torch, colormap=CityScapesSegmentation.get_colormap()),\n",
    "    resize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 20\n",
    "start = time.perf_counter()\n",
    "for _ in range(num_images): # \"_\" -> ループの中で変数が使われていないことを表す記号\n",
    "    compiled_model_onnx([normalized_input_image])\n",
    "end = time.perf_counter()\n",
    "time_onnx = end - start\n",
    "print(\n",
    "    f\"ONNX model in Inference Engine/CPU: {time_onnx/num_images:.3f}\"\n",
    "    f\"seconds per image, FPS: {num_images/time_onnx:.2f}\"\n",
    ")\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(num_images):\n",
    "    compiled_model_ir([input_image])\n",
    "end = time.perf_counter()\n",
    "time_ir = end - start\n",
    "print(\n",
    "    f\"IR model in Inference Engine/CPU: {time_ir/num_images:.3f}\"\n",
    "    f\"seconds per image, FPS: {num_images/time_ir:.2f}\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(num_images):\n",
    "        model(torch.as_tensor(input_image).float())\n",
    "    end = time.perf_counter()\n",
    "    time_torch = end - start\n",
    "print(\n",
    "    f\"PyTorch model on CPU: {time_torch/num_images:.3f} seconds per image,\"\n",
    "    f\"FPS: {num_images/time_torch:.2f}\"\n",
    ")\n",
    "\n",
    "if \"GPU\" in ie.available_devices:\n",
    "    compiled_model_onnx_gpu = ie.compile_model(model=model_onnx, device_name=\"GPU\")\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(num_images):\n",
    "        compiled_model_onnx_gpu([input_image])\n",
    "    end = time.perf_counter()\n",
    "    time_onnx_gpu = end - start\n",
    "\n",
    "    print(\n",
    "        f\"ONNX model in Inference Engine/GPU: {time_onnx_gpu/num_images:.3f}\"\n",
    "        f\"seconds per image {num_images/time_onnx_gpu:.2f}\"\n",
    "    )\n",
    "\n",
    "    compiled_model_ir_gpu = ie.compile_model(model=model_ir, device_name=\"GPU\")\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(num_images):\n",
    "        compiled_model_ir_gpu([input_image])\n",
    "    end = time.perf_counter()\n",
    "    time_ir_gpu = end - start\n",
    "\n",
    "    print(\n",
    "        f\"IR model in Inference Engine/GPU: {time_ir_gpu/num_images:.3f}\"\n",
    "        f\"seconds per image, FPS: {num_images/time_ir_gpu:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show device information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = ie.available_devices\n",
    "for device in devices:\n",
    "    device_name = ie.get_property(device_name=device, name=\"FULL_DEVIDCE_NAME\")\n",
    "    print(f\"{device}: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### メモ\n",
    "\n",
    "処理時間の計測方法\n",
    "- perf_counter()・・・パフォーマンスカウンターを取得する\n",
    "- process_time()・・・CPUの処理時間を求める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc688668df90e2da2c6fe127a4fae0fc63e05cce4be11dcfea3b7cd731a68cc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
