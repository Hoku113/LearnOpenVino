{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from openvino.runtime import Core\n",
    "\n",
    "sys.path.append('../utils')\n",
    "from notebook_utils import segmentation_map_to_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "ie = Core()\n",
    "\n",
    "model = ie.read_model('./intel/road-segmentation-adas-0001/FP32/road-segmentation-adas-0001.xml')\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "input_layer_ir = next(iter(compiled_model.inputs))\n",
    "output_layer_ir = next(iter(compiled_model.outputs))\n",
    "\n",
    "print(input_layer_ir)\n",
    "print(output_layer_ir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Image\n",
    "image = cv2.imread('./data/empty_road_mapillary.jpg')\n",
    "\n",
    "rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_h, image_w, _ = image.shape\n",
    "\n",
    "# N, C, H, W = batch size, number of channels, height, width\n",
    "N, C, H, W = input_layer_ir.shape\n",
    "\n",
    "# resize image\n",
    "resize_image = cv2.resize(image, (W, H))\n",
    "\n",
    "# reshape to network input shape\n",
    "input_image = np.expand_dims(\n",
    "    resize_image.transpose(2, 0, 1), 0\n",
    ")\n",
    "\n",
    "plt.imshow(rgb_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the inference\n",
    "result = compiled_model([input_image])[output_layer_ir]\n",
    "\n",
    "# prepare data for visualization\n",
    "segmentation_mask = np.argmax(result, axis=1)\n",
    "# print(segmentation_mask.shape)\n",
    "# plt.imshow(segmentation_mask.transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = np.array([[68, 1, 84], [48, 103, 141], [53, 183, 120], [199, 216, 52]])\n",
    "\n",
    "# Define ht etransparency of the segmentation mask on the photo\n",
    "alpha = 0.3\n",
    "\n",
    "# Use function from notebook_utils.py to transform mask to an RGB image\n",
    "mask = segmentation_map_to_image(segmentation_mask, colormap)\n",
    "resized_mask = cv2.resize(mask, (image_w, image_h))\n",
    "\n",
    "image_with_mask = cv2.addWeighted(resized_mask, alpha, rgb_img, 1 - alpha, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Base Photo\": rgb_img, \"Segmentation\": mask, \"Masked Photo\": image_with_mask}\n",
    "\n",
    "fig, axs = plt.subplots(1, len(data.items()), figsize=(15, 10))\n",
    "\n",
    "# Fill subplot\n",
    "for ax, (name, image) in zip(axs, data.items()):\n",
    "    ax.axis('off')\n",
    "    ax.set_title(name)\n",
    "    ax.imshow(image)\n",
    "\n",
    "# Display image\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37cba68cc0666ff0500346fbbc272670c42c6c1b2383619b4dcb2ba70df940d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
